#!/usr/bin/env node

/**
 * ATLAS Real Vision Analysis Test
 * Ğ ĞµĞ°Ğ»ÑŒĞ½Ğµ Ñ‚ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ñ€Ğ¾Ğ·Ğ¿Ñ–Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ½Ñ Ğ· Ğ¶Ğ¸Ğ²Ğ¸Ğ¼ Vision API
 *
 * Ğ”Ğ°Ñ‚Ğ°: 17.10.2025
 */

import { execSync } from 'child_process';
import { readFileSync, unlinkSync, existsSync } from 'fs';
import axios from 'axios';

const COLORS = {
    green: '\x1b[32m',
    red: '\x1b[31m',
    yellow: '\x1b[33m',
    blue: '\x1b[34m',
    cyan: '\x1b[36m',
    reset: '\x1b[0m'
};

console.log(`${COLORS.blue}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLORS.reset}`);
console.log(`${COLORS.blue}   ATLAS Real Vision Analysis Test${COLORS.reset}`);
console.log(`${COLORS.blue}   Ğ ĞµĞ°Ğ»ÑŒĞ½Ğµ Ñ‚ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ· Ollama llama3.2-vision${COLORS.reset}`);
console.log(`${COLORS.blue}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLORS.reset}\n`);

async function testVisionWithOllama() {
    const screenshotPath = '/tmp/atlas_test_vision.png';

    try {
        // 1. Ğ¡Ñ‚Ğ²Ğ¾Ñ€Ğ¸Ñ‚Ğ¸ screenshot Desktop (smaller resolution)
        console.log(`${COLORS.cyan}ğŸ“¸ Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ screenshot Desktop...${COLORS.reset}`);
        execSync(`screencapture -x ${screenshotPath}`, { stdio: 'ignore' });

        // Ğ¡Ñ‚Ğ¸ÑĞ½ÑƒÑ‚Ğ¸ Ğ´Ğ¾ Ñ€Ğ¾Ğ·ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ¾Ğ·Ğ¼Ñ–Ñ€Ñƒ (max 1024x1024)
        const tempPath = '/tmp/atlas_test_vision_resized.png';
        execSync(`sips -Z 1024 ${screenshotPath} --out ${tempPath}`, { stdio: 'ignore' });
        execSync(`mv ${tempPath} ${screenshotPath}`, { stdio: 'ignore' });

        const fileSize = execSync(`ls -lh ${screenshotPath} | awk '{print $5}'`).toString().trim();
        console.log(`${COLORS.green}âœ… Screenshot ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¾ Ñ‚Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ñ–Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: ${screenshotPath} (${fileSize})${COLORS.reset}\n`);

        // 2. ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ² base64
        console.log(`${COLORS.cyan}ğŸ”„ ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚ÑƒÑ Ğ² base64...${COLORS.reset}`);
        const imageBuffer = readFileSync(screenshotPath);
        const base64Image = imageBuffer.toString('base64');
        console.log(`${COLORS.green}âœ… Base64 Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¹ (${Math.round(base64Image.length / 1024)}KB)${COLORS.reset}\n`);

        // 3. Ğ’Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ‚Ğ¸ Ollama Vision API Ğ½Ğ°Ğ¿Ñ€ÑĞ¼Ñƒ
        console.log(`${COLORS.cyan}ğŸ¤– Ğ’Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ Ollama llama3.2-vision...${COLORS.reset}`);

        const prompt = `ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒĞ¹ Ñ†ĞµĞ¹ screenshot macOS Desktop Ñ‚Ğ° Ğ¾Ğ¿Ğ¸ÑˆĞ¸ Ñ‰Ğ¾ Ñ‚Ğ¸ Ğ±Ğ°Ñ‡Ğ¸Ñˆ:
1. Ğ¯ĞºĞ° Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ñ–Ğ¹Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°?
2. Ğ¯ĞºÑ– Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¸ Ğ²Ñ–Ğ´ĞºÑ€Ğ¸Ñ‚Ñ–?
3. Ğ©Ğ¾ Ğ²Ğ¸Ğ´Ğ½Ğ¾ Ğ½Ğ° ĞµĞºÑ€Ğ°Ğ½Ñ–?
4. Ğ¯ĞºĞ¸Ğ¹ Ñ‡Ğ°Ñ Ğ´Ğ½Ñ (light/dark mode)?
5. Ğ„ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ Ğ¼ĞµĞ½Ñ Ğ·Ğ²ĞµÑ€Ñ…Ñƒ?

Ğ”Ğ°Ğ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºÑƒ ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ.`;

        const startTime = Date.now();

        const response = await axios.post('http://localhost:11434/api/generate', {
            model: 'llama3.2-vision',
            prompt: prompt,
            images: [base64Image],
            stream: false,
            options: {
                temperature: 0.2,
                num_predict: 500
            }
        }, {
            timeout: 120000,  // 120s Ğ´Ğ»Ñ Ğ²ĞµĞ»Ğ¸ĞºĞ¸Ñ… Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½ÑŒ
            headers: { 'Content-Type': 'application/json' }
        });

        const elapsed = Date.now() - startTime;

        // 4. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
        console.log(`${COLORS.green}âœ… Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ğ½Ğ° Ğ·Ğ° ${(elapsed / 1000).toFixed(1)}s${COLORS.reset}\n`);

        console.log(`${COLORS.yellow}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLORS.reset}`);
        console.log(`${COLORS.yellow}   Ollama Vision Analysis Result:${COLORS.reset}`);
        console.log(`${COLORS.yellow}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLORS.reset}\n`);

        console.log(response.data.response);

        console.log(`\n${COLORS.yellow}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLORS.reset}\n`);

        // 5. ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        console.log(`${COLORS.cyan}ğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸:${COLORS.reset}`);
        console.log(`   Model:           llama3.2-vision (10.7B params)`);
        console.log(`   Provider:        Ollama (local, FREE)`);
        console.log(`   Response time:   ${(elapsed / 1000).toFixed(1)}s`);
        console.log(`   Image size:      ${fileSize}`);
        console.log(`   Base64 size:     ${Math.round(base64Image.length / 1024)}KB`);
        console.log(`   Cost:            $0 (FREE!)${COLORS.reset}\n`);

        console.log(`${COLORS.green}âœ… SUCCESS: Vision Recognition Ğ¿Ñ€Ğ°Ñ†ÑÑ” Ñ–Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾!${COLORS.reset}`);

        // Cleanup
        if (existsSync(screenshotPath)) {
            unlinkSync(screenshotPath);
        }

    } catch (error) {
        console.error(`${COLORS.red}âŒ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ°: ${error.message}${COLORS.reset}`);

        if (error.response) {
            console.error(`${COLORS.red}Response: ${JSON.stringify(error.response.data, null, 2)}${COLORS.reset}`);
        }

        process.exit(1);
    }
}

// Run test
testVisionWithOllama();
