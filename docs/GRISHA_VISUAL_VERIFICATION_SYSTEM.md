# Grisha Visual Verification System

## –î–∞—Ç–∞: 17.10.2025
## –í–µ—Ä—Å—ñ—è: 5.0.0

---

## üìã –û–≥–ª—è–¥

**Grisha Visual Verification** - –ø–æ–≤–Ω—ñ—Å—Ç—é –ø–µ—Ä–µ—Ä–æ–±–ª —Å–∏—Å—Ç–µ–º–∞ –≤–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—ó, —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î AI vision –∑–∞–º—ñ—Å—Ç—å MCP —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ–≤ –¥–ª—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–≤–¥–∞–Ω—å.

### –ö–ª—é—á–æ–≤—ñ –∑–º—ñ–Ω–∏:

#### ‚ùå –í–∏–¥–∞–ª–µ–Ω–æ (–°—Ç–∞—Ä–∞ —Å–∏—Å—Ç–µ–º–∞ - MCP Tools):
- MCP tool selection –¥–ª—è –≤–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
- –ó–∞–ª–µ–∂–Ω—ñ—Å—Ç—å –≤—ñ–¥ playwright/filesystem/shell MCP servers
- Tool-based evidence collection
- Hardcoded —Å–ø–∏—Å–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö tools

#### ‚úÖ –î–æ–¥–∞–Ω–æ (–ù–æ–≤–∞ —Å–∏—Å—Ç–µ–º–∞ - Visual AI):
- Continuous screenshot monitoring (VisualCaptureService)
- GPT-4 Vision AI analysis (VisionAnalysisService)
- Visual evidence-based verification
- Stuck state detection —á–µ—Ä–µ–∑ –≤—ñ–∑—É–∞–ª—å–Ω–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥
- Dynamic feedback —á–µ—Ä–µ–∑ –≤—ñ–∑—É–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑

---

## üèóÔ∏è –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ —Å–∏—Å—Ç–µ–º–∏:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Grisha Visual Verification              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ  1. VisualCaptureService                       ‚îÇ
‚îÇ     ‚îú‚îÄ captureScreenshot()                     ‚îÇ
‚îÇ     ‚îú‚îÄ startMonitoring()                       ‚îÇ
‚îÇ     ‚îú‚îÄ stopMonitoring()                        ‚îÇ
‚îÇ     ‚îú‚îÄ compareScreenshots()                    ‚îÇ
‚îÇ     ‚îî‚îÄ detectChanges() (MD5 hash)             ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  2. VisionAnalysisService                      ‚îÇ
‚îÇ     ‚îú‚îÄ analyzeScreenshot() ‚Üí GPT-4V           ‚îÇ
‚îÇ     ‚îú‚îÄ compareScreenshots()                    ‚îÇ
‚îÇ     ‚îú‚îÄ detectStuckState()                      ‚îÇ
‚îÇ     ‚îî‚îÄ _callVisionAPI() ‚Üí API                 ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  3. GrishaVerifyItemProcessor                  ‚îÇ
‚îÇ     ‚îú‚îÄ execute() - Main workflow              ‚îÇ
‚îÇ     ‚îú‚îÄ detectStuckState()                      ‚îÇ
‚îÇ     ‚îú‚îÄ _determineNextAction()                  ‚îÇ
‚îÇ     ‚îî‚îÄ _generateVerificationSummary()          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Workflow –í—ñ–∑—É–∞–ª—å–Ω–æ—ó –í–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—ó

### 1. –ë–∞–∑–æ–≤–∏–π Flow (Per TODO Item):

```javascript
// Grisha –æ—Ç—Ä–∏–º—É—î –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –≤–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
const context = {
    currentItem: { 
        id: 1, 
        action: "–í—ñ–¥–∫—Ä–∏—Ç–∏ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä",
        success_criteria: "–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –≤—ñ–¥–∫—Ä–∏—Ç–æ —Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ" 
    },
    execution: { results: [...] }
};

// 1. –ó–∞—Ö–æ–ø–ª–µ–Ω–Ω—è —Å–∫—Ä—ñ–Ω—à–æ—Ç—É
const screenshot = await visualCapture.captureScreenshot('item_1_verify');
// ‚Üí –ó–±–µ—Ä—ñ–≥–∞—î: /tmp/atlas_visual/screenshot_item_1_verify_1729124567890.png

// 2. AI Vision –∞–Ω–∞–ª—ñ–∑
const visionAnalysis = await visionAnalysis.analyzeScreenshot(
    screenshot.filepath,
    "–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –≤—ñ–¥–∫—Ä–∏—Ç–æ —Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ",
    { action: "–í—ñ–¥–∫—Ä–∏—Ç–∏ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä", executionResults: [...] }
);

// 3. –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª—ñ–∑—É
{
    verified: true,
    confidence: 95,
    reason: "–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä —á—ñ—Ç–∫–æ –≤–∏–¥–Ω–æ –Ω–∞ —Å–∫—Ä—ñ–Ω—à–æ—Ç—ñ, –ø—Ä–æ–≥—Ä–∞–º–∞ –∞–∫—Ç–∏–≤–Ω–∞",
    visual_evidence: {
        observed: "–ü—Ä–æ–≥—Ä–∞–º–∞ –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –≤—ñ–¥–∫—Ä–∏—Ç–∞ –Ω–∞ –ø–µ—Ä–µ–¥–Ω—å–æ–º—É –ø–ª–∞–Ω—ñ",
        matches_criteria: true,
        details: "–í—ñ–∫–Ω–æ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ –∑–∞–π–º–∞—î —Ü–µ–Ω—Ç—Ä –µ–∫—Ä–∞–Ω—É, –≤—Å—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ UI –≤–∏–¥–∏–º—ñ"
    }
}

// 4. –†—ñ—à–µ–Ω–Ω—è
if (visionAnalysis.verified && visionAnalysis.confidence >= 70) {
    return { verified: true, nextAction: 'continue' };
}
```

### 2. Stuck State Detection:

```javascript
// –ó–∞–ø—É—Å–∫ continuous monitoring
await visualCapture.startMonitoring(); // Screenshot –∫–æ–∂–Ω—ñ 2 —Å–µ–∫

// –ü—ñ—Å–ª—è 10+ —Å–µ–∫—É–Ω–¥ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
const stuckAnalysis = await grishaProcessor.detectStuckState(item, 10000);

// –†–µ–∑—É–ª—å—Ç–∞—Ç
{
    stuck: true,
    confidence: 85,
    reason: "–ü—Ä–æ—Ü–µ—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–≤–∏—Å–Ω—É–≤ - –≤—ñ–∑—É–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ",
    visual_evidence: {
        progress_indicators: [],
        stuck_indicators: ["Spinner –Ω–µ –æ–±–µ—Ä—Ç–∞—î—Ç—å—Å—è", "UI –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–µ –æ–Ω–æ–≤–ª—é—é—Ç—å—Å—è"],
        last_change_detected: "8 —Å–µ–∫—É–Ω–¥ —Ç–æ–º—É"
    },
    recommendation: "–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–∏ –ø—Ä–æ—Ü–µ—Å –∞–±–æ –∑–º—ñ–Ω–∏—Ç–∏ –ø—ñ–¥—Ö—ñ–¥"
}

// –î–∏–Ω–∞–º—ñ—á–Ω–∏–π feedback –¥–æ Tetyana
if (stuckAnalysis.stuck) {
    await atlas.adjustTodoItem(item, stuckAnalysis.recommendation);
}
```

---

## üì∏ VisualCaptureService

### –ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:
Continuous screenshot monitoring —Ç–∞ change detection

### –ú–µ—Ç–æ–¥–∏:

#### `async initialize()`
```javascript
await visualCapture.initialize();
// –°—Ç–≤–æ—Ä—é—î /tmp/atlas_visual/ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é
```

#### `async captureScreenshot(context, options)`
```javascript
const screenshot = await visualCapture.captureScreenshot('verify_item_1');
// Returns:
{
    filepath: "/tmp/atlas_visual/screenshot_verify_item_1_1729124567890.png",
    filename: "screenshot_verify_item_1_1729124567890.png",
    timestamp: 1729124567890,
    size: 524288, // bytes
    hash: "5d41402abc4b2a76b9719d911017c592", // MD5
    context: "verify_item_1",
    changed: true // –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–º
}
```

#### `async startMonitoring()` / `async stopMonitoring()`
```javascript
// –ó–∞–ø—É—Å–∫ continuous monitoring (–∫–æ–∂–Ω—ñ 2 —Å–µ–∫)
await visualCapture.startMonitoring();

// –ó—É–ø–∏–Ω–∫–∞
await visualCapture.stopMonitoring();
```

#### `getLatestScreenshot()`
```javascript
const latest = visualCapture.getLatestScreenshot();
// Returns: –æ—Å—Ç–∞–Ω–Ω—ñ–π screenshot info object
```

#### `getScreenshotsSince(timestamp)`
```javascript
const recent = visualCapture.getScreenshotsSince(Date.now() - 10000);
// Returns: –≤—Å—ñ screenshots –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 10 —Å–µ–∫—É–Ω–¥
```

#### `async compareScreenshots(path1, path2)`
```javascript
const comparison = await visualCapture.compareScreenshots(
    '/tmp/atlas_visual/screenshot_1.png',
    '/tmp/atlas_visual/screenshot_2.png'
);
// Returns:
{
    identical: false,
    hash1: "abc123...",
    hash2: "def456...",
    diffBytes: 102400,
    diffPercentage: "19.53",
    significantChange: true // > 5% threshold
}
```

### –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è:

```javascript
const config = {
    captureInterval: 2000,              // –Ü–Ω—Ç–µ—Ä–≤–∞–ª monitoring (ms)
    screenshotDir: '/tmp/atlas_visual', // –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è
    maxStoredScreenshots: 10,           // –ú–∞–∫—Å–∏–º—É–º screenshots —É queue
    changeDetectionThreshold: 0.05,     // 5% change –¥–ª—è significant
    platform: 'darwin'                  // macOS (auto-detect)
};
```

### Platform Support:

- **macOS (darwin)**: `screencapture -x "/path/to/file.png"`
- **Linux**: `scrot "/path/to/file.png"` –∞–±–æ `import -window root "/path/to/file.png"`

---

## ü§ñ VisionAnalysisService

### –ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:
AI-powered visual analysis —á–µ—Ä–µ–∑ GPT-4 Vision API

### –ú–µ—Ç–æ–¥–∏:

#### `async analyzeScreenshot(path, successCriteria, context)`
```javascript
const analysis = await visionAnalysis.analyzeScreenshot(
    '/tmp/atlas_visual/screenshot.png',
    '–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –ø–æ–∫–∞–∑—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç 666',
    { action: '–í–∏–∫–æ–Ω–∞—Ç–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫', executionResults: [...] }
);

// Returns:
{
    verified: true,
    confidence: 100,
    reason: "–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –≤—ñ–¥–∫—Ä–∏—Ç–∏–π —Ç–∞ –ø–æ–∫–∞–∑—É—î –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
    visual_evidence: {
        observed: "–ü—Ä–æ–≥—Ä–∞–º–∞ –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –∞–∫—Ç–∏–≤–Ω–∞, –Ω–∞ –¥–∏—Å–ø–ª–µ—ó '666'",
        matches_criteria: true,
        details: "–ß–∏—Å–ª–æ 666 —á—ñ—Ç–∫–æ –≤–∏–¥–Ω–æ –Ω–∞ –¥–∏—Å–ø–ª–µ—ó –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞"
    },
    suggestions: null
}
```

#### `async compareScreenshots(path1, path2, expectedChange)`
```javascript
const comparison = await visionAnalysis.compareScreenshots(
    '/tmp/before.png',
    '/tmp/after.png',
    '–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –º–∞—î –ø–æ–∫–∞–∑–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç'
);

// Returns:
{
    changeDetected: true,
    matchesExpectedChange: true,
    confidence: 95,
    differences: ["–î–∏—Å–ø–ª–µ–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ –∑–º—ñ–Ω–∏–≤—Å—è –∑ '0' –Ω–∞ '666'"],
    visual_evidence: "–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î—Ç—å—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ",
    explanation: "–ó–º—ñ–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –æ—á—ñ–∫—É–≤–∞–Ω—ñ–π - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑'—è–≤–∏–≤—Å—è"
}
```

#### `async detectStuckState(screenshotPaths, expectedActivity)`
```javascript
const detection = await visionAnalysis.detectStuckState(
    ['/tmp/shot1.png', '/tmp/shot2.png', '/tmp/shot3.png'],
    '–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–µ–±-—Å—Ç–æ—Ä—ñ–Ω–∫–∏'
);

// Returns:
{
    stuck: true,
    confidence: 90,
    reason: "–Ü–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è –º—ñ–∂ –∫–∞–¥—Ä–∞–º–∏",
    visual_evidence: {
        progress_indicators: [],
        stuck_indicators: ["Spinner –≤ –æ–¥–Ω–æ–º—É –ø–æ–ª–æ–∂–µ–Ω–Ω—ñ", "UI –∑–∞–º–æ—Ä–æ–∂–µ–Ω–∏–π"],
        last_change_detected: "–ë—ñ–ª—å—à–µ 6 —Å–µ–∫—É–Ω–¥ —Ç–æ–º—É"
    },
    recommendation: "–ü–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É –∞–±–æ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∑'—î–¥–Ω–∞–Ω–Ω—è"
}
```

### GPT-4 Vision API Integration:

#### Request Format:
```javascript
POST http://localhost:4000/v1/chat/completions
{
    model: "gpt-4-vision-preview",
    messages: [{
        role: "user",
        content: [
            { type: "text", text: "System prompt + user prompt" },
            { 
                type: "image_url", 
                image_url: {
                    url: "data:image/png;base64,iVBORw0KGgoAAAANS...",
                    detail: "high"
                }
            }
        ]
    }],
    max_tokens: 1000,
    temperature: 0.2
}
```

#### Response Parsing:
```javascript
// Handles markdown-wrapped JSON
const content = response.data.choices[0].message.content;

// Cleans: ```json { ... } ``` ‚Üí { ... }
const cleaned = content
    .replace(/^```json\s*/i, '')
    .replace(/^```\s*/i, '')
    .replace(/\s*```$/i, '')
    .trim();

const result = JSON.parse(cleaned);
```

### –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è:

```javascript
const config = {
    visionModel: 'gpt-4-vision-preview',
    apiEndpoint: 'http://localhost:4000/v1/chat/completions',
    maxTokens: 1000,
    temperature: 0.2,           // –ù–∏–∑—å–∫–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ
    imageDetailLevel: 'high',   // 'low', 'high', 'auto'
    timeout: 60000             // 60 —Å–µ–∫—É–Ω–¥
};
```

---

## üéØ GrishaVerifyItemProcessor

### –ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:
–û—Å–Ω–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å–æ—Ä –≤—ñ–∑—É–∞–ª—å–Ω–æ—ó –≤–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è TODO items

### –ù–æ–≤—ñ –º–µ—Ç–æ–¥–∏:

#### `async execute(context)`
```javascript
const result = await grishaProcessor.execute({
    currentItem: { id: 1, action: "...", success_criteria: "..." },
    execution: { results: [...] },
    todo: { items: [...] }
});

// Returns:
{
    success: true,
    verified: true,
    verification: {
        verified: true,
        confidence: 95,
        reason: "...",
        visual_evidence: {...},
        screenshot_path: "/tmp/atlas_visual/...",
        from_visual_analysis: true
    },
    summary: "‚úÖ –í—ñ–∑—É–∞–ª—å–Ω–æ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–æ: ...",
    nextAction: "continue", // 'continue' | 'retry' | 'adjust'
    metadata: {
        itemId: 1,
        verified: true,
        confidence: 95,
        visualEvidence: true,
        verificationMethod: 'visual_ai'
    }
}
```

#### `async detectStuckState(item, durationMs)`
```javascript
const stuck = await grishaProcessor.detectStuckState(item, 10000);
// –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ:
// 1. –ó–∞–ø—É—Å–∫–∞—î monitoring —è–∫—â–æ –Ω–µ –∞–∫—Ç–∏–≤–Ω–∏–π
// 2. –ó–±–∏—Ä–∞—î screenshots –∑–∞ 10 —Å–µ–∫—É–Ω–¥
// 3. –ê–Ω–∞–ª—ñ–∑—É—î —á–µ—Ä–µ–∑ GPT-4 Vision
// 4. –ü–æ–≤–µ—Ä—Ç–∞—î stuck detection result
```

#### `getStatus()`
```javascript
const status = grishaProcessor.getStatus();
// Returns:
{
    initialized: true,
    visualCapture: {
        isMonitoring: false,
        captureInterval: 2000,
        queueSize: 5,
        changeDetected: false
    },
    visionAnalysis: {
        initialized: true,
        visionModel: "gpt-4-vision-preview",
        apiEndpoint: "http://localhost:4000/v1/chat/completions"
    }
}
```

---

## üìù Grisha Visual Prompt

**–§–∞–π–ª:** `prompts/mcp/grisha_visual_verify_item.js`

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–ø—Ç—É:

#### System Prompt:
```javascript
`–¢–∏ –ì—Ä–∏—à–∞ - –≤—ñ–∑—É–∞–ª—å–Ω–∏–π –≤–µ—Ä–∏—Ñ—ñ–∫–∞—Ç–æ—Ä —è–∫–æ—Å—Ç—ñ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è.

**–¢–í–û–Ø –†–û–õ–¨ - –í–Ü–ó–£–ê–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–¢–ò–ö:**
–ê–Ω–∞–ª—ñ–∑—É–π SCREENSHOT –¥–ª—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–≤–¥–∞–Ω–Ω—è.
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò –≤—ñ–∑—É–∞–ª—å–Ω—ñ –¥–æ–∫–∞–∑–∏ –∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.

**–ö–†–ò–¢–ï–†–Ü–á VERIFIED = TRUE:**
‚úÖ –í—ñ–∑—É–∞–ª—å–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ —É—Å–ø—ñ—Ö—É –ü–†–ò–°–£–¢–ù–Ü –Ω–∞ —Å–∫—Ä—ñ–Ω—à–æ—Ç—ñ
‚úÖ Success Criteria –ø–æ–≤–Ω—ñ—Å—Ç—é –≤–∏–∫–æ–Ω–∞–Ω–æ
‚úÖ –í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å >= 70%

**–ö–†–ò–¢–ï–†–Ü–á VERIFIED = FALSE:**
‚ùå –í—ñ–∑—É–∞–ª—å–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ —É—Å–ø—ñ—Ö—É –í–Ü–î–°–£–¢–ù–Ü
‚ùå Success Criteria –ù–ï –≤–∏–∫–æ–Ω–∞–Ω–æ
‚ùå –í–∏–¥–Ω–æ –ø–æ–º–∏–ª–∫–∏, –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Å—Ç–∞–Ω

[5 –¥–µ—Ç–∞–ª—å–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –≤—ñ–∑—É–∞–ª—å–Ω–æ—ó –≤–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—ó]
`
```

#### User Prompt:
```javascript
`**TODO Item:** {{item_action}}
**Success Criteria:** {{success_criteria}}
**Execution Results Summary:** {{execution_results}}

Analyze the screenshot and verify if the task was completed successfully.
Return ONLY raw JSON.`
```

#### Output Format:
```json
{
  "verified": true,
  "confidence": 95,
  "reason": "–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –≤—ñ–¥–∫—Ä–∏—Ç–∏–π —Ç–∞ –ø–æ–∫–∞–∑—É—î –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
  "visual_evidence": {
    "observed": "–ü—Ä–æ–≥—Ä–∞–º–∞ –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –∞–∫—Ç–∏–≤–Ω–∞, –Ω–∞ –¥–∏—Å–ø–ª–µ—ó '666'",
    "matches_criteria": true,
    "details": "–ß–∏—Å–ª–æ 666 —á—ñ—Ç–∫–æ –≤–∏–¥–Ω–æ –Ω–∞ –¥–∏—Å–ø–ª–µ—ó –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞"
  },
  "suggestions": null
}
```

---

## üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

### Unit Tests:

```bash
# Visual Capture Service
npm test tests/unit/visual-capture-service.test.js

# Vision Analysis Service  
npm test tests/unit/vision-analysis-service.test.js

# Grisha Processor
npm test tests/unit/grisha-verify-item-processor.test.js
```

### Integration Tests:

```bash
# Full visual verification workflow
npm test tests/integration/visual-verification.test.js
```

### Manual Testing:

```javascript
// 1. –ó–∞–ø—É—Å—Ç–∏—Ç–∏ orchestrator
node orchestrator/server.js

// 2. –ù–∞–¥—ñ—Å–ª–∞—Ç–∏ —Ç–µ—Å—Ç–æ–≤–µ –∑–∞–≤–¥–∞–Ω–Ω—è
curl -X POST http://localhost:5101/chat/stream \
  -H "Content-Type: application/json" \
  -d '{
    "message": "–í—ñ–¥–∫—Ä–∏–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä —ñ –≤–∏–∫–æ–Ω–∞–π —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ 22 * 30.27",
    "sessionId": "test_visual"
  }'

// 3. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ screenshots
ls -lh /tmp/atlas_visual/

// 4. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ª–æ–≥–∏
tail -f logs/orchestrator.log | grep VISUAL-GRISHA
```

---

## üö® Troubleshooting

### Problem: Screenshot capture fails

**Symptom:** `Screenshot file is empty` –∞–±–æ `screencapture command failed`

**Solution:**
```bash
# macOS: –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –¥–æ–∑–≤–æ–ª–∏ Screen Recording
System Preferences ‚Üí Security & Privacy ‚Üí Screen Recording ‚Üí Enable for Terminal/Node

# Linux: –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ scrot –∞–±–æ imagemagick
sudo apt-get install scrot imagemagick
```

### Problem: GPT-4 Vision API not available

**Symptom:** `Vision API endpoint not available`

**Solution:**
```bash
# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —â–æ API server –∑–∞–ø—É—â–µ–Ω–∏–π
curl http://localhost:4000/health

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
grep VISION config/global-config.js
```

### Problem: Low confidence scores

**Symptom:** –í—Å—ñ verification results –º–∞—é—Ç—å confidence < 70%

**Solution:**
1. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —è–∫—ñ—Å—Ç—å screenshots (—Ä–æ–∑–º—ñ—Ä, —á—ñ—Ç–∫—ñ—Å—Ç—å)
2. –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—å —â–æ success criteria —á—ñ—Ç–∫—ñ —Ç–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ
3. –ó–±—ñ–ª—å—à–∏—Ç–∏ `imageDetailLevel` –¥–æ 'high' –≤ config
4. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —â–æ screenshot captured –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –º–æ–º–µ–Ω—Ç

---

## üìä Performance Metrics

### Typical Timings:

- **Screenshot Capture**: 50-200ms (macOS screencapture)
- **GPT-4 Vision Analysis**: 2-5 seconds (API call + processing)
- **Total Verification Time**: 2-6 seconds per item

### Resource Usage:

- **Disk Space**: ~500KB per screenshot, max 10 stored = ~5MB
- **Memory**: ~50MB for visual services
- **API Calls**: 1 per verification + optional stuck detection

### Optimization Tips:

1. **Reuse screenshots**: –Ø–∫—â–æ –¥–≤–∞ items –ø–µ—Ä–µ–≤—ñ—Ä—è—é—Ç—å —Ç–æ–π —Å–∞–º–∏–π —Å—Ç–∞–Ω
2. **Adjust capture interval**: –ó–±—ñ–ª—å—à–∏—Ç–∏ –¥–æ 3-5 —Å–µ–∫ –¥–ª—è less active tasks
3. **Use 'low' detail level**: –î–ª—è simple UI verification (—à–≤–∏–¥—à–µ)
4. **Batch stuck detection**: –ü–µ—Ä–µ–≤—ñ—Ä—è—Ç–∏ stuck state —Ç—ñ–ª—å–∫–∏ –ø—ñ—Å–ª—è 3+ items failed

---

## üîÑ Migration from MCP Tools

### Before (MCP Tools):
```javascript
// Grisha –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤ MCP tools
const verification = await mcpTodoManager.verifyItem(item, execution, {
    toolsSummary: mcpManager.getToolsSummary()
});

// –ü—Ä–∏–∫–ª–∞–¥: filesystem__read_file –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
{
    verified: true,
    reason: "–§–∞–π–ª –º—ñ—Å—Ç–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç",
    evidence: { tool: "filesystem__read_file", ... }
}
```

### After (Visual AI):
```javascript
// Grisha –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î AI vision
const verification = await grishaProcessor.execute({
    currentItem: item,
    execution,
    todo
});

// –ü—Ä–∏–∫–ª–∞–¥: GPT-4 Vision –∞–Ω–∞–ª—ñ–∑—É—î screenshot
{
    verified: true,
    confidence: 95,
    reason: "–§–∞–π–ª —á—ñ—Ç–∫–æ –≤–∏–¥–Ω–æ –Ω–∞ Desktop",
    visual_evidence: {
        observed: "–Ü–∫–æ–Ω–∫–∞ —Ñ–∞–π–ª—É 'test.txt' –ø—Ä–∏—Å—É—Ç–Ω—è –Ω–∞ Desktop",
        matches_criteria: true
    }
}
```

### Migration Checklist:

- [ ] Update `orchestrator/workflow/stages/grisha-verify-item-processor.js`
- [ ] Replace MCP tool calls with visual verification
- [ ] Update prompts to use `grisha_visual_verify_item.js`
- [ ] Register visual services in DI container
- [ ] Test verification accuracy
- [ ] Monitor API costs (GPT-4 Vision)
- [ ] Update documentation

---

## üìö References

- **GPT-4 Vision API**: https://platform.openai.com/docs/guides/vision
- **macOS screencapture**: `man screencapture`
- **ATLAS Copilot Instructions**: `.github/copilot-instructions.md`

---

## üéì Best Practices

### ‚úÖ DO:
- Always capture screenshots at verification time (not reuse old ones)
- Use specific success criteria (not vague descriptions)
- Set confidence threshold appropriate to task criticality
- Log visual evidence for debugging
- Handle API failures gracefully

### ‚ùå DON'T:
- Don't verify without visual evidence
- Don't use low detail level for complex UI
- Don't trust verification with confidence < 50%
- Don't skip error handling for API calls
- Don't store unlimited screenshots (manage queue size)

---

**–ê–≤—Ç–æ—Ä:** ATLAS Development Team  
**–í–µ—Ä—Å—ñ—è –¥–æ–∫—É–º–µ–Ω—Ç—É:** 1.0  
**–û—Å—Ç–∞–Ω–Ω—î –æ–Ω–æ–≤–ª–µ–Ω–Ω—è:** 17.10.2025
