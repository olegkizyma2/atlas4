# Model Configuration Fix - Available Models Only

**–î–∞—Ç–∞:** 14.10.2025 ~04:00  
**–ü—Ä–æ–±–ª–µ–º–∞:** –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏—Ö Anthropic –º–æ–¥–µ–ª–µ–π  
**–†—ñ—à–µ–Ω–Ω—è:** –ó–∞–º—ñ–Ω–∞ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ñ OpenAI –º–æ–¥–µ–ª—ñ –∑ localhost:4000

---

## üö® –ü—Ä–æ–±–ª–µ–º–∞

**–°–∏–º–ø—Ç–æ–º:**
- –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –º—ñ—Å—Ç–∏–ª–∞ `anthropic/claude-3-5-sonnet-20241022`
- –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –º—ñ—Å—Ç–∏–ª–∞ `anthropic/claude-3-5-haiku-20241022`
- –¶—ñ –º–æ–¥–µ–ª—ñ **–ù–ï –¥–æ—Å—Ç—É–ø–Ω—ñ** —á–µ—Ä–µ–∑ localhost:4000 API

**–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π:**
```bash
curl -s http://localhost:4000/v1/models | jq -r '.data[].id'
# Anthropic –ù–ï –≤ —Å–ø–∏—Å–∫—É!
```

**–§–∞–π–ª:** `config/global-config.js`

**Affected stages:**
1. `AI_MODEL_CONFIG.models.analysis` - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤ Claude Sonnet
2. `MCP_MODEL_CONFIG.stages.todo_planning` - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤ Claude Sonnet
3. `MCP_MODEL_CONFIG.stages.adjust_todo` - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤ Claude Haiku

---

## ‚úÖ –†—ñ—à–µ–Ω–Ω—è

### 1. Analysis Stage (AI_MODEL_CONFIG)

**–ë—É–ª–æ:**
```javascript
analysis: {
  model: 'anthropic/claude-3-5-sonnet-20241022',  // ‚ùå –ù–ï –¥–æ—Å—Ç—É–ø–Ω–∞
  temperature: 0.3,
  max_tokens: 1000,
  description: 'Claude Sonnet –¥–ª—è —è–∫—ñ—Å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É —Ç–∞ reasoning'
}
```

**–°—Ç–∞–ª–æ:**
```javascript
analysis: {
  model: 'openai/o1-mini',  // ‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞ reasoning model
  temperature: 0.3,
  max_tokens: 1000,
  description: 'OpenAI o1-mini –¥–ª—è —è–∫—ñ—Å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É —Ç–∞ reasoning'
}
```

**–ß–æ–º—É o1-mini:**
- ‚úÖ –°–ø–µ—Ü—ñ–∞–ª—å–Ω–æ —Ä–æ–∑—Ä–æ–±–ª–µ–Ω–∞ –¥–ª—è reasoning tasks
- ‚úÖ –®–≤–∏–¥—à–∞ —Ç–∞ –¥–µ—à–µ–≤—à–∞ –∑–∞ o1
- ‚úÖ –Ø–∫—ñ—Å—Ç—å –∞–Ω–∞–ª—ñ–∑—É –ø–æ—Ä—ñ–≤–Ω—è–Ω–∞ –∑ Claude Sonnet
- ‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ localhost:4000

---

### 2. TODO Planning Stage (MCP_MODEL_CONFIG)

**–ë—É–ª–æ:**
```javascript
todo_planning: {
  get model() { return process.env.MCP_MODEL_TODO_PLANNING || 'anthropic/claude-3-5-sonnet-20241022'; },
  // ...
  description: 'Critical planning - –ø–æ—Ç—Ä—ñ–±–µ–Ω —è–∫—ñ—Å–Ω–∏–π reasoning'
}
```

**–°—Ç–∞–ª–æ:**
```javascript
todo_planning: {
  get model() { return process.env.MCP_MODEL_TODO_PLANNING || 'openai/o1-mini'; },
  // ...
  description: 'Critical planning - o1-mini –¥–ª—è —è–∫—ñ—Å–Ω–æ–≥–æ reasoning'
}
```

**–ß–æ–º—É o1-mini:**
- ‚úÖ TODO planning - –∫—Ä–∏—Ç–∏—á–Ω–∞ –∑–∞–¥–∞—á–∞ —â–æ –ø–æ—Ç—Ä–µ–±—É—î reasoning
- ‚úÖ o1-mini —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —Å–∞–º–µ –¥–ª—è —Ü—å–æ–≥–æ
- ‚úÖ –ö—Ä–∞—â–∞ –Ω—ñ–∂ gpt-4o-mini –¥–ª—è –ø–ª–∞–Ω—É–≤–∞–Ω–Ω—è

---

### 3. Adjust TODO Stage (MCP_MODEL_CONFIG)

**–ë—É–ª–æ:**
```javascript
adjust_todo: {
  get model() { return process.env.MCP_MODEL_ADJUST_TODO || 'anthropic/claude-3-5-haiku-20241022'; },
  // ...
  description: '–ö–æ—Ä–µ–∫—Ü—ñ—è TODO - mid-level reasoning'
}
```

**–°—Ç–∞–ª–æ:**
```javascript
adjust_todo: {
  get model() { return process.env.MCP_MODEL_ADJUST_TODO || 'openai/gpt-4o-mini'; },
  // ...
  description: '–ö–æ—Ä–µ–∫—Ü—ñ—è TODO - gpt-4o-mini (mid-level reasoning)'
}
```

**–ß–æ–º—É gpt-4o-mini:**
- ‚úÖ Adjust - –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞ –∑–∞–¥–∞—á–∞ (—Ç—ñ–ª—å–∫–∏ –∫–æ—Ä–µ–∫—Ü—ñ—è)
- ‚úÖ gpt-4o-mini –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è mid-level reasoning
- ‚úÖ –ï–∫–æ–Ω–æ–º—ñ—è –∫–æ—à—Ç—ñ–≤ –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ Claude Haiku

---

## üìä Comparison

### Anthropic Models (Unavailable)
- ‚ùå `claude-3-5-sonnet-20241022` - –ù–ï –≤ API
- ‚ùå `claude-3-5-haiku-20241022` - –ù–ï –≤ API
- ‚ùå –ë—É–¥—å-—è–∫—ñ —ñ–Ω—à—ñ Claude variants

### OpenAI Alternatives (Available)

**Reasoning Models:**
- ‚úÖ `openai/o1` - –ù–∞–π–ø–æ—Ç—É–∂–Ω—ñ—à–∞ reasoning
- ‚úÖ `openai/o1-mini` - –®–≤–∏–¥—à–∞ reasoning (–û–ë–†–ê–ù–û)
- ‚úÖ `openai/o1-preview` - Preview –≤–µ—Ä—Å—ñ—è
- ‚úÖ `openai/o3` - –ù–æ–≤—ñ—à–∞ reasoning
- ‚úÖ `openai/o3-mini` - –ö–æ–º–ø–∞–∫—Ç–Ω–∞

**Universal Models:**
- ‚úÖ `openai/gpt-4o` - –ü–æ—Ç—É–∂–Ω–∞ universal
- ‚úÖ `openai/gpt-4o-mini` - –®–≤–∏–¥–∫–∞ universal (–û–ë–†–ê–ù–û –¥–ª—è adjust)
- ‚úÖ `openai/gpt-5` - Experimental
- ‚úÖ `openai/gpt-5-mini`

---

## üéØ Final Configuration

**config/global-config.js –ø—ñ—Å–ª—è –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:**

```javascript
// AI_MODEL_CONFIG (system stages)
export const AI_MODEL_CONFIG = {
  models: {
    classification: {
      model: 'openai/gpt-4o-mini',  // –®–≤–∏–¥–∫–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
      temperature: 0.1,
      max_tokens: 50
    },
    
    chat: {
      model: 'openai/gpt-4o-mini',  // –ü—Ä–∏—Ä–æ–¥–Ω—ñ —Ä–æ–∑–º–æ–≤–∏
      temperature: 0.7,
      max_tokens: 500
    },
    
    analysis: {
      model: 'openai/o1-mini',      // FIXED: Reasoning model
      temperature: 0.3,
      max_tokens: 1000
    },
    
    tts_optimization: {
      model: 'openai/gpt-4o-mini',  // TTS optimization
      temperature: 0.2,
      max_tokens: 300
    }
  }
};

// MCP_MODEL_CONFIG (MCP stages)
export const MCP_MODEL_CONFIG = {
  stages: {
    mode_selection: {
      model: 'openai/gpt-4o-mini'   // –ë—ñ–Ω–∞—Ä–Ω–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
    },
    
    backend_selection: {
      model: 'openai/gpt-4o-mini'   // Keyword routing
    },
    
    todo_planning: {
      model: 'openai/o1-mini'       // FIXED: Critical reasoning
    },
    
    plan_tools: {
      model: 'openai/gpt-4o-mini'   // Tool matching (optimized)
    },
    
    verify_item: {
      model: 'openai/gpt-4o-mini'   // Success/fail check
    },
    
    adjust_todo: {
      model: 'openai/gpt-4o-mini'   // FIXED: Mid-level reasoning
    },
    
    final_summary: {
      model: 'openai/gpt-4o-mini'   // User-facing summary
    }
  }
};
```

---

## üìà Benefits

### Availability
- ‚úÖ –í—Å—ñ –º–æ–¥–µ–ª—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ —á–µ—Ä–µ–∑ localhost:4000
- ‚úÖ –ù–µ–º–∞—î dependency –Ω–∞ Anthropic API
- ‚úÖ –ü—Ä–∞—Ü—é—î offline –∑ –ª–æ–∫–∞–ª—å–Ω–∏–º proxy

### Performance
- ‚úÖ o1-mini —à–≤–∏–¥—à–∞ –∑–∞ Claude Sonnet –¥–ª—è reasoning
- ‚úÖ gpt-4o-mini –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö tasks
- ‚úÖ –ú–µ–Ω—à–µ latency —á–µ—Ä–µ–∑ —î–¥–∏–Ω–∏–π API

### Cost
- ‚úÖ o1-mini –¥–µ—à–µ–≤—à–∞ –∑–∞ Claude Sonnet
- ‚úÖ gpt-4o-mini –Ω–∞–π–¥–µ—à–µ–≤—à–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö –∑–∞–¥–∞—á
- ‚úÖ –ù–µ–º–∞—î –ø–æ–¥–≤—ñ–π–Ω–æ–≥–æ –±—ñ–ª–ª—ñ–Ω–≥—É (OpenAI + Anthropic)

### Reliability
- ‚úÖ –û–¥–∏–Ω API endpoint - –ø—Ä–æ—Å—Ç—ñ—à–µ monitoring
- ‚úÖ –ù–µ–º–∞—î rate limits –≤—ñ–¥ Anthropic
- ‚úÖ –Ñ–¥–∏–Ω–∏–π fallback mechanism

---

## üß™ Testing

### Verify No Anthropic References
```bash
grep -E "(anthropic|claude)" config/global-config.js
# –ú–∞—î –±—É—Ç–∏ –ø—É—Å—Ç–æ!
```

### Check Model Configuration
```bash
grep "model: '" config/global-config.js | grep -v "//"
# –ú–∞—î –ø–æ–∫–∞–∑–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ openai/* –º–æ–¥–µ–ª—ñ
```

### Test API Availability
```bash
# Test o1-mini
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/o1-mini",
    "messages": [{"role": "user", "content": "Test reasoning"}],
    "max_tokens": 100
  }'

# Test gpt-4o-mini
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-4o-mini",
    "messages": [{"role": "user", "content": "Test"}],
    "max_tokens": 50
  }'
```

### Integration Test
```bash
# Restart orchestrator
cd orchestrator && node server.js

# Send request that triggers analysis stage
curl -X POST http://localhost:5101/chat/stream \
  -H "Content-Type: application/json" \
  -d '{"message": "–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü–µ–π –∫–æ–¥", "sessionId": "test"}'

# Check logs for o1-mini usage
tail -f logs/orchestrator.log | grep -E "(o1-mini|analysis)"
```

---

## üö® Critical Rules

### ‚úÖ DO: Use Available Models

**–ó–ê–í–ñ–î–ò** –ø–µ—Ä–µ–≤—ñ—Ä—è–π—Ç–µ —â–æ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞:
```bash
curl -s http://localhost:4000/v1/models | jq -r '.data[].id' | grep "MODEL_NAME"
```

### ‚úÖ DO: Match Model to Task

- **Reasoning tasks** ‚Üí `openai/o1-mini` or `openai/o1`
- **Simple tasks** ‚Üí `openai/gpt-4o-mini`
- **Universal tasks** ‚Üí `openai/gpt-4o`
- **Critical tasks** ‚Üí `openai/o1` or `openai/gpt-4o`

### ‚ùå DON'T: Hardcode Unavailable Models

**–ù–Ü–ö–û–õ–ò** –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –º–æ–¥–µ–ª—ñ —â–æ –ù–ï –≤ —Å–ø–∏—Å–∫—É:
```javascript
// ‚ùå BAD
model: 'anthropic/claude-3-5-sonnet'  // Not available!

// ‚úÖ GOOD
model: 'openai/o1-mini'  // Available and suitable
```

### ‚ö†Ô∏è Watch: API Changes

–ü–µ—Ä—ñ–æ–¥–∏—á–Ω–æ –ø–µ—Ä–µ–≤—ñ—Ä—è–π—Ç–µ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π:
```bash
curl -s http://localhost:4000/v1/models | jq -r '.data[].id'
```

---

## üìö –ü–æ–≤'—è–∑–∞–Ω—ñ –î–æ–∫—É–º–µ–Ω—Ç–∏

- `docs/AVAILABLE_MODELS_REFERENCE.md` - –ü–æ–≤–Ω–∏–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
- `docs/MCP_PROMPT_OPTIMIZATION_2025-10-14.md` - Prompt optimization
- `config/global-config.js` - –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

---

## üîÑ Changelog

**14.10.2025 ~04:00** - Model availability fix
- Identified: Anthropic models not in API list
- Replaced: Claude Sonnet ‚Üí o1-mini (reasoning)
- Replaced: Claude Haiku ‚Üí gpt-4o-mini (mid-tier)
- Verified: All models available —á–µ—Ä–µ–∑ localhost:4000
- Tested: No anthropic references remain
- Result: ‚úÖ Configuration uses only available models

---

**–°—Ç–∞—Ç—É—Å:** ‚úÖ FIXED  
**–ù–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫:** Restart orchestrator ‚Üí Test all stages work with new models
