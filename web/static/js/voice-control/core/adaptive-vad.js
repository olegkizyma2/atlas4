/**
 * @fileoverview Adaptive Voice Activity Detection –∑ ML –º–æ–∂–ª–∏–≤–æ—Å—Ç—è–º–∏
 * –†–µ–∞–ª—ñ–∑—É—î –∞–¥–∞–ø—Ç–∏–≤–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏ VAD –∑ environmental adaptation —Ç–∞ user personalization
 * Patterns: Strategy + Adapter + Observer + ML Pipeline + Feature Engineering
 * 
 * Enhanced with Speaker Recognition (2025-10-11):
 * - Voice timbre analysis for user vs background speaker detection
 * - Pitch pattern matching for speaker identification
 * - Integration with SpeakerRecognitionSystem
 */

import { VoiceLogger } from '../utils/voice-logger.js';
import { Events } from '../events/event-manager.js';
import { speakerRecognition } from './speaker-profile.js';

/**
 * @typedef {Object} AudioFeatures
 * @property {number} rms - Root Mean Square –µ–Ω–µ—Ä–≥—ñ—ó
 * @property {number} snr - Signal-to-Noise Ratio
 * @property {number} spectralCentroid - –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∏–π —Ü–µ–Ω—Ç—Ä–æ—ó–¥
 * @property {number} zeroCrossingRate - –®–≤–∏–¥–∫—ñ—Å—Ç—å –ø–µ—Ä–µ—Ç–∏–Ω—É –Ω—É–ª—è
 * @property {number} spectralRolloff - –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∏–π rolloff
 * @property {Float32Array} mfcc - Mel-frequency cepstral coefficients
 * @property {Float32Array} spectralFlux - –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∏–π flux
 */

/**
 * @typedef {Object} VADResult
 * @property {boolean} isVoiceActive - –ß–∏ –∞–∫—Ç–∏–≤–Ω–∏–π –≥–æ–ª–æ—Å
 * @property {number} confidence - –í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å [0-1]
 * @property {string} method - –ú–µ—Ç–æ–¥ –¥–µ—Ç–µ–∫—Ü—ñ—ó
 * @property {AudioFeatures} features - –í–∏—Ç—è–≥–Ω—É—Ç—ñ –æ–∑–Ω–∞–∫–∏
 * @property {Object} reasoning - –ü–æ—è—Å–Ω–µ–Ω–Ω—è —Ä—ñ—à–µ–Ω–Ω—è
 */

/**
 * Feature Extractor –¥–ª—è –∞—É–¥—ñ–æ —Å–∏–≥–Ω–∞–ª—É
 */
export class AudioFeatureExtractor {
  constructor(config = {}) {
    this.config = {
      sampleRate: 44100,
      fftSize: 2048,
      melBands: 13,
      ...config
    };

    this.logger = new VoiceLogger('AudioFeatureExtractor');
  }

  /**
     * –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∏—Ö –æ–∑–Ω–∞–∫ –∑ –∞—É–¥—ñ–æ –±—É—Ñ–µ—Ä–∞
     */
  extractFeatures(audioBuffer, audioContext = null) {
    const features = {};

    try {
      // –ë–∞–∑–æ–≤—ñ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –æ–∑–Ω–∞–∫–∏
      features.rms = this.calculateRMS(audioBuffer);
      features.zeroCrossingRate = this.calculateZeroCrossingRate(audioBuffer);

      // –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏ (–ø–æ—Ç—Ä–µ–±—É—é—Ç—å FFT)
      if (audioContext) {
        const spectrum = this.performFFT(audioBuffer, audioContext);
        features.spectralCentroid = this.calculateSpectralCentroid(spectrum);
        features.spectralRolloff = this.calculateSpectralRolloff(spectrum);
        features.spectralFlux = this.calculateSpectralFlux(spectrum);
        features.mfcc = this.calculateMFCC(spectrum);
      }

      // SNR –æ–±—á–∏—Å–ª–µ–Ω–Ω—è (–ø–æ—Ç—Ä–µ–±—É—î baseline noise)
      features.snr = this.calculateSNR(audioBuffer, features.rms);

      return features;

    } catch (error) {
      this.logger.error('Feature extraction failed', { error: error.message });
      return this.getDefaultFeatures();
    }
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è RMS –µ–Ω–µ—Ä–≥—ñ—ó
     * @private
     */
  calculateRMS(buffer) {
    let sum = 0;
    for (let i = 0; i < buffer.length; i++) {
      sum += buffer[i] * buffer[i];
    }
    return Math.sqrt(sum / buffer.length);
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è Zero Crossing Rate
     * @private
     */
  calculateZeroCrossingRate(buffer) {
    let crossings = 0;
    for (let i = 1; i < buffer.length; i++) {
      if ((buffer[i] >= 0) !== (buffer[i - 1] >= 0)) {
        crossings++;
      }
    }
    return crossings / (buffer.length - 1);
  }

  /**
     * –í–∏–∫–æ–Ω–∞–Ω–Ω—è FFT –¥–ª—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
     * @private
     */
  performFFT(buffer, audioContext) {
    // –ü—Ä–æ—Å—Ç–∏–π FFT –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ AnalyserNode
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = this.config.fftSize;

    const spectrum = new Float32Array(analyser.frequencyBinCount);
    analyser.getFloatFrequencyData(spectrum);

    return spectrum;
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞
     * @private
     */
  calculateSpectralCentroid(spectrum) {
    let weightedSum = 0;
    let magnitudeSum = 0;

    for (let i = 0; i < spectrum.length; i++) {
      const magnitude = Math.abs(spectrum[i]);
      weightedSum += i * magnitude;
      magnitudeSum += magnitude;
    }

    return magnitudeSum > 0 ? weightedSum / magnitudeSum : 0;
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ rolloff
     * @private
     */
  calculateSpectralRolloff(spectrum, threshold = 0.85) {
    const totalEnergy = spectrum.reduce((sum, val) => sum + Math.abs(val), 0);
    const targetEnergy = totalEnergy * threshold;

    let cumulativeEnergy = 0;
    for (let i = 0; i < spectrum.length; i++) {
      cumulativeEnergy += Math.abs(spectrum[i]);
      if (cumulativeEnergy >= targetEnergy) {
        return i / spectrum.length;
      }
    }

    return 1.0;
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ flux
     * @private
     */
  calculateSpectralFlux(spectrum, previousSpectrum = null) {
    if (!previousSpectrum) {
      return new Float32Array(spectrum.length);
    }

    const flux = new Float32Array(spectrum.length);
    for (let i = 0; i < spectrum.length; i++) {
      const diff = Math.abs(spectrum[i]) - Math.abs(previousSpectrum[i]);
      flux[i] = Math.max(0, diff); // –¢—ñ–ª—å–∫–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ñ —Ä—ñ–∑–Ω–∏—Ü—ñ
    }

    return flux;
  }

  /**
     * –°–ø—Ä–æ—â–µ–Ω–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è MFCC
     * @private
     */
  calculateMFCC(spectrum) {
    const melBands = this.config.melBands;
    const mfcc = new Float32Array(melBands);

    // –°–ø—Ä–æ—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è MFCC - –ª–æ–≥–∞—Ä–∏—Ñ–º mel-scale —Ñ—ñ–ª—å—Ç—Ä—ñ–≤
    const melFilterBank = this.createMelFilterBank(spectrum.length, melBands);

    for (let i = 0; i < melBands; i++) {
      let energy = 0;
      for (let j = 0; j < spectrum.length; j++) {
        energy += Math.abs(spectrum[j]) * melFilterBank[i][j];
      }
      mfcc[i] = Math.log(Math.max(energy, 1e-10));
    }

    return mfcc;
  }

  /**
     * –°—Ç–≤–æ—Ä–µ–Ω–Ω—è Mel filter bank
     * @private
     */
  createMelFilterBank(spectrumLength, numBands) {
    const filterBank = [];
    const melMin = this.hzToMel(0);
    const melMax = this.hzToMel(this.config.sampleRate / 2);
    const melStep = (melMax - melMin) / (numBands + 1);

    for (let i = 0; i < numBands; i++) {
      const filter = new Float32Array(spectrumLength);
      const leftMel = melMin + i * melStep;
      const centerMel = melMin + (i + 1) * melStep;
      const rightMel = melMin + (i + 2) * melStep;

      const leftHz = this.melToHz(leftMel);
      const centerHz = this.melToHz(centerMel);
      const rightHz = this.melToHz(rightMel);

      for (let j = 0; j < spectrumLength; j++) {
        const freq = j * this.config.sampleRate / (2 * spectrumLength);

        if (freq >= leftHz && freq <= centerHz) {
          filter[j] = (freq - leftHz) / (centerHz - leftHz);
        } else if (freq > centerHz && freq <= rightHz) {
          filter[j] = (rightHz - freq) / (rightHz - centerHz);
        }
      }

      filterBank.push(filter);
    }

    return filterBank;
  }

  /**
     * –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è Hz –≤ Mel
     * @private
     */
  hzToMel(hz) {
    return 2595 * Math.log10(1 + hz / 700);
  }

  /**
     * –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è Mel –≤ Hz
     * @private
     */
  melToHz(mel) {
    return 700 * (Math.pow(10, mel / 2595) - 1);
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è SNR
     * @private
     */
  calculateSNR(buffer, rms) {
    // –°–ø—Ä–æ—â–µ–Ω–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è SNR
    const noiseFloor = 0.01; // –ë–∞–∑–æ–≤–∏–π –ø–æ—Ä—ñ–≥ —à—É–º—É
    return rms > 0 ? 20 * Math.log10(rms / noiseFloor) : -Infinity;
  }

  /**
     * –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö –æ–∑–Ω–∞–∫ –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
     * @private
     */
  getDefaultFeatures() {
    return {
      rms: 0,
      snr: -Infinity,
      spectralCentroid: 0,
      zeroCrossingRate: 0,
      spectralRolloff: 0,
      spectralFlux: new Float32Array(0),
      mfcc: new Float32Array(this.config.melBands)
    };
  }
}

/**
 * Environment Profile –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü—ñ—ó –¥–æ —É–º–æ–≤ –æ—Ç–æ—á–µ–Ω–Ω—è
 */
export class EnvironmentProfile {
  constructor() {
    this.profile = {
      baselineNoise: 0,
      averageRMS: 0,
      averageSNR: 0,
      spectralCharacteristics: new Float32Array(13),
      adaptationRate: 0.01,
      sampleCount: 0
    };

    this.logger = new VoiceLogger('EnvironmentProfile');
  }

  /**
     * –û–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –æ—Ç–æ—á–µ–Ω–Ω—è
     */
  updateProfile(features) {
    const rate = this.profile.adaptationRate;

    // Exponential moving average –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü—ñ—ó
    this.profile.averageRMS = this.exponentialMovingAverage(
      this.profile.averageRMS,
      features.rms,
      rate
    );

    this.profile.averageSNR = this.exponentialMovingAverage(
      this.profile.averageSNR,
      features.snr,
      rate
    );

    // –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
    if (features.mfcc && features.mfcc.length === this.profile.spectralCharacteristics.length) {
      for (let i = 0; i < features.mfcc.length; i++) {
        this.profile.spectralCharacteristics[i] = this.exponentialMovingAverage(
          this.profile.spectralCharacteristics[i],
          features.mfcc[i],
          rate
        );
      }
    }

    this.profile.sampleCount++;

    // –ê–¥–∞–ø—Ç–∞—Ü—ñ—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ –Ω–∞–≤—á–∞–Ω–Ω—è
    if (this.profile.sampleCount > 1000) {
      this.profile.adaptationRate = Math.max(0.001, this.profile.adaptationRate * 0.99);
    }
  }

  /**
     * Exponential moving average
     * @private
     */
  exponentialMovingAverage(current, newValue, rate) {
    if (isNaN(newValue) || !isFinite(newValue)) return current;
    return current * (1 - rate) + newValue * rate;
  }

  /**
     * –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∞–¥–∞–ø—Ç–∏–≤–Ω–∏—Ö –ø–æ—Ä–æ–≥—ñ–≤
     */
  getAdaptiveThresholds() {
    const baseRMSThreshold = Math.max(0.01, this.profile.averageRMS * 2);
    const baseSNRThreshold = Math.max(-20, this.profile.averageSNR - 10);

    return {
      rmsThreshold: baseRMSThreshold,
      snrThreshold: baseSNRThreshold,
      adaptationConfidence: Math.min(1.0, this.profile.sampleCount / 1000)
    };
  }

  /**
     * –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –æ—Ç–æ—á–µ–Ω–Ω—è
     */
  getProfile() {
    return { ...this.profile };
  }
}

/**
 * User Profile –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–∞—Ü—ñ—ó –ø—ñ–¥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
 */
export class UserProfile {
  constructor() {
    this.voiceCharacteristics = {
      averagePitch: 0,
      voiceEnergy: 0,
      speechRate: 0,
      spectralSignature: new Float32Array(13),
      sampleCount: 0
    };

    this.logger = new VoiceLogger('UserProfile');
  }

  /**
     * –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
     */
  updateVoiceCharacteristics(features, isVoice = true) {
    if (!isVoice) return; // –û–Ω–æ–≤–ª—é—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –¥–µ—Ç–µ–∫—Ü—ñ—ó –≥–æ–ª–æ—Å—É

    const rate = 0.05; // –ü–æ–≤—ñ–ª—å–Ω—ñ—à–∞ –∞–¥–∞–ø—Ç–∞—Ü—ñ—è –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

    this.voiceCharacteristics.voiceEnergy = this.exponentialMovingAverage(
      this.voiceCharacteristics.voiceEnergy,
      features.rms,
      rate
    );

    // –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ—ó —Å–∏–≥–Ω–∞—Ç—É—Ä–∏
    if (features.mfcc && features.mfcc.length === this.voiceCharacteristics.spectralSignature.length) {
      for (let i = 0; i < features.mfcc.length; i++) {
        this.voiceCharacteristics.spectralSignature[i] = this.exponentialMovingAverage(
          this.voiceCharacteristics.spectralSignature[i],
          features.mfcc[i],
          rate
        );
      }
    }

    this.voiceCharacteristics.sampleCount++;
  }

  /**
     * Exponential moving average
     * @private
     */
  exponentialMovingAverage(current, newValue, rate) {
    if (isNaN(newValue) || !isFinite(newValue)) return current;
    return current * (1 - rate) + newValue * rate;
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å—Ö–æ–∂–æ—Å—Ç—ñ –∑ –ø—Ä–æ—Ñ—ñ–ª–µ–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
     */
  calculateVoiceSimilarity(features) {
    if (this.voiceCharacteristics.sampleCount < 10) {
      return 0.5; // –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
    }

    let similarity = 0;
    let comparisons = 0;

    // –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –µ–Ω–µ—Ä–≥—ñ—ó
    if (features.rms > 0 && this.voiceCharacteristics.voiceEnergy > 0) {
      const energyRatio = Math.min(features.rms, this.voiceCharacteristics.voiceEnergy) /
                              Math.max(features.rms, this.voiceCharacteristics.voiceEnergy);
      similarity += energyRatio;
      comparisons++;
    }

    // –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ—ó —Å–∏–≥–Ω–∞—Ç—É—Ä–∏ (—Å–ø—Ä–æ—â–µ–Ω–µ)
    if (features.mfcc && features.mfcc.length === this.voiceCharacteristics.spectralSignature.length) {
      let spectralSimilarity = 0;
      let validComparisons = 0;

      for (let i = 0; i < features.mfcc.length; i++) {
        if (!isNaN(features.mfcc[i]) && !isNaN(this.voiceCharacteristics.spectralSignature[i])) {
          const diff = Math.abs(features.mfcc[i] - this.voiceCharacteristics.spectralSignature[i]);
          spectralSimilarity += Math.exp(-diff); // Gaussian-like similarity
          validComparisons++;
        }
      }

      if (validComparisons > 0) {
        similarity += spectralSimilarity / validComparisons;
        comparisons++;
      }
    }

    return comparisons > 0 ? similarity / comparisons : 0.5;
  }
}

/**
 * Adaptive Voice Activity Detection
 */
export class AdaptiveVAD {
  constructor(config = {}) {
    this.config = {
      traditionWeight: 0.4,
      spectralWeight: 0.3,
      temporalWeight: 0.2,
      userWeight: 0.1,
      confidenceThreshold: 0.7,
      adaptationEnabled: true,
      ...config
    };

    this.featureExtractor = new AudioFeatureExtractor(config.features);
    this.environmentProfile = new EnvironmentProfile();
    this.userProfile = new UserProfile();

    this.previousSpectrum = null;
    this.detectionHistory = [];

    this.logger = new VoiceLogger('AdaptiveVAD');
  }

  /**
     * –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –≥–æ–ª–æ—Å–æ–≤–æ—ó –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
     * Enhanced with speaker recognition (2025-10-11)
     */
  detectVoiceActivity(audioBuffer, audioContext = null) {
    try {
      // –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫
      const features = this.featureExtractor.extractFeatures(audioBuffer, audioContext);

      // –û–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—ñ–≤ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
      if (this.config.adaptationEnabled) {
        this.environmentProfile.updateProfile(features);
      }

      // Multi-modal –¥–µ—Ç–µ–∫—Ü—ñ—è
      const results = {
        traditional: this.traditionalVAD(features),
        spectral: this.spectralVAD(features),
        temporal: this.temporalVAD(features),
        user: this.userBasedVAD(features)
      };

      // Speaker recognition check (enhanced)
      let speakerResult = null;
      let isUserSpeaking = true;
      
      if (this.config.enableSpeakerRecognition !== false && typeof speakerRecognition !== 'undefined') {
        speakerResult = speakerRecognition.identifySpeaker(features);
        isUserSpeaking = speakerResult.matchesUser;
        
        // Log speaker detection
        if (speakerResult.confidence > 0.5) {
          this.logger.info(`üé§ Speaker: ${speakerResult.speakerId} (${(speakerResult.confidence * 100).toFixed(1)}%)`, {
            isUser: speakerResult.isUser,
            matchesUser: speakerResult.matchesUser
          });
        }
      }

      // Ensemble –ø—ñ–¥—Ö—ñ–¥
      let confidence = this.calculateEnsembleConfidence(results);
      let isActive = confidence > this.config.confidenceThreshold;

      // Filter out background speakers
      if (isActive && !isUserSpeaking && this.config.filterBackgroundSpeakers !== false) {
        this.logger.warn('üö´ Voice detected but not from user - filtering background speaker');
        isActive = false;
        confidence *= 0.5; // Reduce confidence for background speaker
      }

      // –û–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
      if (isActive && isUserSpeaking) {
        this.userProfile.updateVoiceCharacteristics(features, true);
        
        // Learn user voice for speaker recognition
        if (typeof speakerRecognition !== 'undefined' && this.config.enableSpeakerRecognition !== false) {
          speakerRecognition.learnUserVoice(features);
        }
      }

      // –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó
      this.updateDetectionHistory(isActive, confidence, features);

      const vadResult = {
        isActive,
        confidence,
        method: 'adaptive_ensemble',
        features,
        breakdown: results,
        speakerResult,
        isUserSpeaking,
        adaptation: this.getAdaptationMetrics(),
        reasoning: this.generateReasoning(results, confidence, isActive, speakerResult)
      };

      this.logger.debug('VAD result', {
        isActive,
        confidence: Math.round(confidence * 100) / 100,
        isUserSpeaking,
        breakdown: Object.fromEntries(
          Object.entries(results).map(([k, v]) => [k, Math.round(v * 100) / 100])
        )
      });

      return vadResult;

    } catch (error) {
      this.logger.error('VAD detection failed', { error: error.message });
      return this.getDefaultVADResult();
    }
  }

  /**
     * –¢—Ä–∞–¥–∏—Ü—ñ–π–Ω–∏–π VAD –Ω–∞ –æ—Å–Ω–æ–≤—ñ RMS —Ç–∞ SNR
     * @private
     */
  traditionalVAD(features) {
    const thresholds = this.environmentProfile.getAdaptiveThresholds();

    const rmsActive = features.rms > thresholds.rmsThreshold;
    const snrActive = features.snr > thresholds.snrThreshold;

    // –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    let confidence = 0;
    if (rmsActive) confidence += 0.6;
    if (snrActive) confidence += 0.4;

    return Math.min(1.0, confidence);
  }

  /**
     * –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∏–π VAD
     * @private
     */
  spectralVAD(features) {
    let confidence = 0;

    // –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∏–π —Ü–µ–Ω—Ç—Ä–æ—ó–¥ (–≥–æ–ª–æ—Å –∑–∞–∑–≤–∏—á–∞–π –º–∞—î –≤–∏—â–∏–π —Ü–µ–Ω—Ç—Ä–æ—ó–¥)
    if (features.spectralCentroid > 0.3) {
      confidence += 0.4;
    }

    // Zero crossing rate (–≥–æ–ª–æ—Å –º–∞—î –ø–æ–º—ñ—Ä–Ω–∏–π ZCR)
    if (features.zeroCrossingRate > 0.05 && features.zeroCrossingRate < 0.3) {
      confidence += 0.3;
    }

    // –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∏–π rolloff
    if (features.spectralRolloff > 0.2 && features.spectralRolloff < 0.8) {
      confidence += 0.3;
    }

    return Math.min(1.0, confidence);
  }

  /**
     * –¢–µ–º–ø–æ—Ä–∞–ª—å–Ω–∏–π VAD
     * @private
     */
  temporalVAD(features) {
    // –ê–Ω–∞–ª—ñ–∑ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ flux –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –∑–º—ñ–Ω
    if (!features.spectralFlux || features.spectralFlux.length === 0) {
      return 0.5;
    }

    const avgFlux = features.spectralFlux.reduce((a, b) => a + b, 0) / features.spectralFlux.length;

    // –ì–æ–ª–æ—Å –∑–∞–∑–≤–∏—á–∞–π –º–∞—î –ø–æ–º—ñ—Ä–Ω–∏–π flux
    if (avgFlux > 0.1 && avgFlux < 1.0) {
      return 0.8;
    } else if (avgFlux > 0.05) {
      return 0.6;
    }

    return 0.2;
  }

  /**
     * User-based VAD –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –ø—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
     * @private
     */
  userBasedVAD(features) {
    const similarity = this.userProfile.calculateVoiceSimilarity(features);

    // –í–∏—Å–æ–∫–µ similarity –æ–∑–Ω–∞—á–∞—î —Å—Ö–æ–∂—ñ—Å—Ç—å –∑ –≥–æ–ª–æ—Å–æ–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    return similarity;
  }

  /**
     * –û–±—á–∏—Å–ª–µ–Ω–Ω—è ensemble confidence
     * @private
     */
  calculateEnsembleConfidence(results) {
    const weights = {
      traditional: this.config.traditionWeight,
      spectral: this.config.spectralWeight,
      temporal: this.config.temporalWeight,
      user: this.config.userWeight
    };

    let weightedSum = 0;
    let totalWeight = 0;

    for (const [method, confidence] of Object.entries(results)) {
      const weight = weights[method] || 0;
      weightedSum += confidence * weight;
      totalWeight += weight;
    }

    return totalWeight > 0 ? weightedSum / totalWeight : 0;
  }

  /**
     * –û–Ω–æ–≤–ª–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó –¥–µ—Ç–µ–∫—Ü—ñ—ó
     * @private
     */
  updateDetectionHistory(isActive, confidence, features) {
    this.detectionHistory.push({
      isActive,
      confidence,
      timestamp: Date.now(),
      rms: features.rms
    });

    // –û–±–º–µ–∂–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É —ñ—Å—Ç–æ—Ä—ñ—ó
    if (this.detectionHistory.length > 100) {
      this.detectionHistory = this.detectionHistory.slice(-50);
    }
  }

  /**
     * –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è —Ä—ñ—à–µ–Ω–Ω—è
     * Enhanced with speaker recognition (2025-10-11)
     * @private
     */
  generateReasoning(results, confidence, isActive, speakerResult = null) {
    const dominantMethod = Object.entries(results)
      .sort(([,a], [,b]) => b - a)[0];

    const reasoning = {
      decision: isActive ? 'voice_detected' : 'no_voice',
      confidence: confidence,
      dominantMethod: dominantMethod[0],
      dominantConfidence: dominantMethod[1],
      factors: {
        traditional: results.traditional > 0.5 ? 'positive' : 'negative',
        spectral: results.spectral > 0.5 ? 'positive' : 'negative',
        temporal: results.temporal > 0.5 ? 'positive' : 'negative',
        user: results.user > 0.5 ? 'positive' : 'negative'
      }
    };

    // Add speaker recognition reasoning
    if (speakerResult) {
      reasoning.speaker = {
        identified: speakerResult.speakerId,
        confidence: speakerResult.confidence,
        isUser: speakerResult.isUser,
        matchesUser: speakerResult.matchesUser
      };
    }

    return reasoning;
  }

  /**
     * –û—Ç—Ä–∏–º–∞–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –∞–¥–∞–ø—Ç–∞—Ü—ñ—ó
     */
  getAdaptationMetrics() {
    const envProfile = this.environmentProfile.getProfile();
    const thresholds = this.environmentProfile.getAdaptiveThresholds();

    return {
      environmentalAdaptation: {
        sampleCount: envProfile.sampleCount,
        baselineNoise: envProfile.baselineNoise,
        adaptationRate: envProfile.adaptationRate,
        currentThresholds: thresholds
      },
      userAdaptation: {
        voiceSamples: this.userProfile.voiceCharacteristics.sampleCount,
        hasProfile: this.userProfile.voiceCharacteristics.sampleCount > 10
      },
      recentHistory: this.detectionHistory.slice(-10).map(h => ({
        isActive: h.isActive,
        confidence: Math.round(h.confidence * 100) / 100
      }))
    };
  }

  /**
     * –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
     * @private
     */
  getDefaultVADResult() {
    return {
      isActive: false,
      confidence: 0.0,
      method: 'default_fallback',
      features: this.featureExtractor.getDefaultFeatures(),
      breakdown: {
        traditional: 0,
        spectral: 0,
        temporal: 0,
        user: 0
      },
      adaptation: this.getAdaptationMetrics(),
      reasoning: {
        decision: 'error_fallback',
        confidence: 0,
        dominantMethod: 'none',
        factors: {}
      }
    };
  }

  /**
     * –°–∫–∏–¥–∞–Ω–Ω—è –∞–¥–∞–ø—Ç–∞—Ü—ñ—ó
     */
  resetAdaptation() {
    this.environmentProfile = new EnvironmentProfile();
    this.userProfile = new UserProfile();
    this.detectionHistory = [];
    this.previousSpectrum = null;

    this.logger.info('Adaptation profiles reset');
  }

  /**
     * –ï–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ—Ñ—ñ–ª—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
     */
  exportProfiles() {
    return {
      environment: this.environmentProfile.getProfile(),
      user: this.userProfile.voiceCharacteristics,
      config: this.config,
      timestamp: Date.now()
    };
  }

  /**
     * –Ü–º–ø–æ—Ä—Ç –ø—Ä–æ—Ñ—ñ–ª—ñ–≤
     */
  importProfiles(profileData) {
    try {
      if (profileData.environment) {
        this.environmentProfile.profile = { ...profileData.environment };
      }

      if (profileData.user) {
        this.userProfile.voiceCharacteristics = { ...profileData.user };
      }

      this.logger.info('Profiles imported successfully');
      return true;
    } catch (error) {
      this.logger.error('Profile import failed', { error: error.message });
      return false;
    }
  }
}

/**
 * –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫—Å–ø–æ—Ä—Ç
 */
export const adaptiveVAD = new AdaptiveVAD();
